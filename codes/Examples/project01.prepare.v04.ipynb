{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "\n",
    "import json\n",
    "\n",
    "import urllib.parse\n",
    "from urllib.parse import unquote\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version IV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BagOfWord and XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Параметры вычислений\n",
    "file_path = '/data/share/project01/gender_age_dataset.txt'\n",
    "file_limit = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 7s, sys: 2.65 s, total: 1min 10s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Процедура. Фильтрует домен из url\n",
    "def toDomain( url ):\n",
    "    if url.startswith('http://http') : url = url[7:]\n",
    "    if url.startswith('http://&referrer=') : url = url[17:]\n",
    "        \n",
    "    parsed_url = urlparse( urllib.parse.unquote( url ).strip() )\n",
    "    if parsed_url.scheme not in ['http','https']: return None\n",
    "\n",
    "    url = parsed_url.netloc.strip()\n",
    "\n",
    "    if url.startswith('www.') : url = url[4:]\n",
    "\n",
    "    dpoint = url.rfind(':')     \n",
    "    if dpoint != -1 : url = url[:dpoint]    \n",
    "\n",
    "    dpoint = url.find('&')     \n",
    "    if dpoint != -1 : url = url[:dpoint]    \n",
    "\n",
    "    dpoint = url.rfind('@')     \n",
    "    if dpoint != -1 : url = url[dpoint+1:]    \n",
    "       \n",
    "    return url if url.rfind('.') != -1 else None\n",
    "\n",
    "#Процедура разбирает JSON и возвращет домен и timestamp\n",
    "def workupDomain( szDomain ):\n",
    "    theCollection = [str(toDomain ( value['url']) ) + ';'   for value in json.loads( szDomain )['visits']]\n",
    "    return  str('').join ( theCollection  ).replace('None;', '').replace('-', '').replace('.', '').replace(';', ' ')\n",
    "\n",
    "# Загружаем файл\n",
    "theUserCorpus = pd.read_csv(file_path, sep='\\t', nrows=file_limit  )\n",
    "theUserCorpus.head()\n",
    "\n",
    "#Перебираем элементы, сохраняя из данных тока домен\n",
    "theUserCorpus['domain'] = theUserCorpus['user_json'].apply( workupDomain )\n",
    "theUserCorpus.drop(['user_json'], axis=1, inplace=True)\n",
    "\n",
    "#формируем мега признак\n",
    "theUserCorpus['target'] = theUserCorpus.gender+theUserCorpus.age\n",
    "theUserCorpus.drop(['gender', 'age'], axis=1, inplace=True )\n",
    "theUserCorpus.set_index(['uid'], inplace=True)\n",
    "\n",
    "#Создаем карту групп признаков: где чего лежит\n",
    "theTargetName = theUserCorpus.target.unique()\n",
    "if len((np.where(theTargetName == '--'))[0] ) == 0 : theTargetName = np.append(theTargetName, ['--']) #Заплатке на частичную выборку\n",
    "theTargetMap = pd.DataFrame( {'code':range(1, len(theTargetName)+1) }, index = theTargetName )\n",
    "theTargetMap.code.loc['--'] = 0\n",
    "theTargetMap.sort_values('code', inplace=True)\n",
    "\n",
    "#Генерируем номера групп согластно карте признаков\n",
    "theUserCorpus['targetID'] = theUserCorpus['target'].apply( lambda x:  theTargetMap.code.loc[x] )\n",
    "theUserCorpus.drop(['target'], axis=1, inplace=True )\n",
    "theUserCorpus.sort_values(by=['targetID'], inplace=True)\n",
    "\n",
    "#Рассчитываем положения их смещения в общем массиве\n",
    "theTargetMap['len'] = theTargetMap['code'].apply( lambda type:  len(theUserCorpus[theUserCorpus.targetID == type]) )\n",
    "theTargetMap['begin'] = [theTargetMap[theTargetMap.code < type ]['len'].sum() \\\n",
    "                        if type > 0 else 0 \\\n",
    "                        for type in range(0, 11) ]\n",
    "theTargetMap['end'] = [theTargetMap[theTargetMap.code <= type ]['len'].sum() \\\n",
    "                        if type > 0 else int(theTargetMap[theTargetMap.code == type ]['len']) \\\n",
    "                        for type in range(0, 11) ]\n",
    "\n",
    "#Эта тупая тварь не сохраняет в файл индексы. Ставим заплатку\n",
    "theUserCorpus.reset_index(inplace=True)\n",
    "theUserCorpus.to_csv('~/project/user_corpus.csv', sep=',', index=False)\n",
    "theTargetMap.to_csv('~/project/target_map.csv', sep=',', index=False)\n",
    "theUserCorpus.set_index(['uid'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Любуемся результатом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>len</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>--</th>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F18-24</th>\n",
       "      <td>1</td>\n",
       "      <td>2886</td>\n",
       "      <td>5000</td>\n",
       "      <td>7886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M25-34</th>\n",
       "      <td>2</td>\n",
       "      <td>8666</td>\n",
       "      <td>7886</td>\n",
       "      <td>16552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F25-34</th>\n",
       "      <td>3</td>\n",
       "      <td>6791</td>\n",
       "      <td>16552</td>\n",
       "      <td>23343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M&gt;=55</th>\n",
       "      <td>4</td>\n",
       "      <td>784</td>\n",
       "      <td>23343</td>\n",
       "      <td>24127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F45-54</th>\n",
       "      <td>5</td>\n",
       "      <td>2597</td>\n",
       "      <td>24127</td>\n",
       "      <td>26724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F35-44</th>\n",
       "      <td>6</td>\n",
       "      <td>4271</td>\n",
       "      <td>26724</td>\n",
       "      <td>30995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M35-44</th>\n",
       "      <td>7</td>\n",
       "      <td>5089</td>\n",
       "      <td>30995</td>\n",
       "      <td>36084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F&gt;=55</th>\n",
       "      <td>8</td>\n",
       "      <td>895</td>\n",
       "      <td>36084</td>\n",
       "      <td>36979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M18-24</th>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>36979</td>\n",
       "      <td>38991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M45-54</th>\n",
       "      <td>10</td>\n",
       "      <td>2147</td>\n",
       "      <td>38991</td>\n",
       "      <td>41138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        code   len  begin    end\n",
       "--         0  5000      0   5000\n",
       "F18-24     1  2886   5000   7886\n",
       "M25-34     2  8666   7886  16552\n",
       "F25-34     3  6791  16552  23343\n",
       "M>=55      4   784  23343  24127\n",
       "F45-54     5  2597  24127  26724\n",
       "F35-44     6  4271  26724  30995\n",
       "M35-44     7  5089  30995  36084\n",
       "F>=55      8   895  36084  36979\n",
       "M18-24     9  2012  36979  38991\n",
       "M45-54    10  2147  38991  41138"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theTargetMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 41138 entries, fe1e01f3-5877-4a34-a300-3cfffc2f48e1 to f16a67ec-5122-4f67-8546-415b22982009\n",
      "Data columns (total 2 columns):\n",
      "domain      41138 non-null object\n",
      "targetID    41138 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 964.2+ KB\n"
     ]
    }
   ],
   "source": [
    "theUserCorpus.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запихиваем данные в мешок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of theCorpus is  41138\n",
      "Size of theBagOfWords is  (41138, 116637)\n",
      "CPU times: user 1min 2s, sys: 2.92 s, total: 1min 4s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Процедура токенизации\n",
    "def tokenise( text ):\n",
    "    words = [word.lower() for word in word_tokenize(text)]\n",
    "    return words\n",
    "\n",
    "#Обучаем векторизатор и генерируем Bag of Words\n",
    "theCorpus = list(theUserCorpus['domain'])\n",
    "print ('Size of theCorpus is ', len(theCorpus) )\n",
    "\n",
    "theVectorizer = CountVectorizer(tokenizer=tokenise)\n",
    "theBagOfWords = theVectorizer.fit_transform(theCorpus).toarray()\n",
    "print('Size of theBagOfWords is ', theBagOfWords.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выделяем диапазон для исследований"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11000, 116637), (11000,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partSize = 1000\n",
    "if partSize is None :\n",
    "    fullData = theBagOfWords[:41138]\n",
    "    fullTarget = (theUserCorpus['targetID'].values)[:41138]\n",
    "else :\n",
    "    fullData = theBagOfWords[:partSize]\n",
    "    fullTarget = (theUserCorpus['targetID'].values)[:partSize]\n",
    "    for type in range(1, 11):\n",
    "        end = theTargetMap[theTargetMap.code == type].len[0]\n",
    "        end = partSize if end >= partSize else end\n",
    "        begin = theTargetMap[theTargetMap.code == type].begin[0]\n",
    "        fullData = np.concatenate((fullData, theBagOfWords[begin:begin+partSize]) )\n",
    "        fullTarget = np.concatenate((fullTarget, (theUserCorpus['targetID'].values)[begin:begin+partSize]))    \n",
    "\n",
    "fullData.shape, fullTarget.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загоняем в xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.43 s, sys: 10.5 s, total: 14 s\n",
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Делим мастер данные на массивы\n",
    "masterData, researchmentData, masterTarget, researchmentTarget = \\\n",
    "    train_test_split(fullData, fullTarget, test_size= 0.33, random_state=33 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04222300908057908\n",
      "CPU times: user 14h 42min 7s, sys: 7min 48s, total: 14h 49min 55s\n",
      "Wall time: 31min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import xgboost\n",
    "\n",
    "# У кого xgboost длиннее тот и прав\n",
    "model = xgboost.XGBRegressor(n_estimators = 100, nthread= -1, max_depth = 6, objective = 'multi:softmax', num_class = 11 ) #\n",
    "model.fit(masterData, masterTarget)\n",
    "print( model.score(masterData, masterTarget) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "researchmentLabel = model.predict(researchmentData)\n",
    "researchmentPredict = model.predict(theBagOfWords[:partSize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          --       0.14      0.05      0.08       349\n",
      "      F18-24       0.21      0.17      0.19       339\n",
      "      M25-34       0.23      0.12      0.16       377\n",
      "      F25-34       0.18      0.08      0.11       328\n",
      "       M>=55       0.22      0.15      0.18       238\n",
      "      F45-54       0.13      0.52      0.21       385\n",
      "      F35-44       0.15      0.10      0.12       307\n",
      "      M35-44       0.17      0.10      0.13       308\n",
      "       F>=55       0.30      0.17      0.21       317\n",
      "      M18-24       0.23      0.29      0.25       334\n",
      "      M45-54       0.21      0.13      0.16       348\n",
      "\n",
      "    accuracy                           0.18      3630\n",
      "   macro avg       0.20      0.17      0.16      3630\n",
      "weighted avg       0.20      0.18      0.16      3630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(researchmentTarget, researchmentLabel, target_names=list(theTargetMap.index)) #['...', '...']\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  8.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  0.,  5.,  5.,  5.,\n",
       "        5.,  5.,  0.,  7.,  0.,  5.,  0.,  0.,  0.,  4.,  5.,  0.,  9.,\n",
       "        5.,  5.,  7.,  0.,  5.,  0.,  7.,  4.,  5.,  0.,  1.,  3.,  0.,\n",
       "        5.,  5.,  5.,  0.,  7.,  0.,  5.,  5.,  6.,  5.,  5.,  1.,  0.,\n",
       "        2.,  5.,  0.,  5.,  8.,  5.,  5.,  0.,  2.,  5.,  4.,  2.,  5.,\n",
       "        2.,  5.,  7.,  0.,  5.,  8.,  0.,  9.,  5.,  0.,  0.,  5.,  8.,\n",
       "        2.,  0.,  9.,  5.,  0.,  4.,  8.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        9.,  0.,  3.,  5.,  5.,  3.,  9.,  9.,  8.,  5.,  8.,  1.,  5.,\n",
       "        5.,  5.,  2.,  5.,  8.,  0.,  0.,  0.,  5.,  0.,  5.,  5.,  9.,\n",
       "        9.,  1.,  5.,  0.,  0.,  5.,  9.,  5.,  5.,  6.,  0.,  1.,  7.,\n",
       "        3.,  0.,  5.,  0.,  5.,  9.,  2.,  0.,  8.,  9.,  5.,  7.,  0.,\n",
       "        1.,  5.,  9.,  5.,  5.,  5.,  0.,  9.,  2.,  5.,  6.,  5.,  5.,\n",
       "        0.,  0.,  0.,  5.,  0.,  9.,  5.,  5.,  0.,  9., 10.,  5.,  0.,\n",
       "        5.,  5.,  6.,  5.,  4.,  0., 10., 10.,  0.,  3.,  3., 10.,  2.,\n",
       "        5.,  4.,  5.,  5.,  6.,  5.,  5.,  9.,  2.,  5.,  5.,  5.,  1.,\n",
       "        5.,  3.,  5.,  5.,  9.,  8.,  5.,  0.,  5.,  1.,  0.,  5.,  5.,\n",
       "        5.,  5.,  5.,  4.,  9.,  3.,  9.,  5.,  9.,  9.,  5.,  5.,  2.,\n",
       "        9.,  0.,  0., 10.,  9.,  1.,  1.,  5.,  5., 10.,  5.,  5.,  0.,\n",
       "        5.,  5.,  9.,  5.,  0.,  0.,  9.,  4.,  3.,  2.,  5.,  9.,  8.,\n",
       "        8.,  5.,  5.,  5.,  9.,  2.,  5.,  0.,  0.,  3.,  5.,  0.,  1.,\n",
       "        5.,  5.,  0.,  5.,  1.,  5.,  5.,  5.,  0.,  5.,  5.,  5.,  9.,\n",
       "        0.,  0.,  5.,  5.,  9.,  1.,  4.,  1.,  5.,  9.,  5.,  9.,  9.,\n",
       "        1., 10.,  0.,  5.,  6.,  5.,  1.,  5.,  9.,  5.,  4.,  5.,  4.,\n",
       "        9.,  9.,  9.,  5.,  5.,  1.,  1.,  0.,  1.,  0.,  5.,  5.,  5.,\n",
       "        0.,  0., 10.,  5.,  3.,  5.,  0.,  2.,  8.,  0.,  2.,  5.,  0.,\n",
       "        5.,  9.,  9.,  0.,  1.,  5.,  0.,  2.,  7.,  5.,  9.,  0.,  0.,\n",
       "        0.,  5.,  2.,  5.,  6., 10.,  1., 10.,  0.,  5.,  5.,  5.,  5.,\n",
       "        0.,  0.,  2.,  0.,  7.,  5.,  5.,  2.,  9.,  5.,  5.,  5.,  8.,\n",
       "        9.,  0.,  5.,  5.,  9.,  0.,  1.,  0.,  5.,  4.,  0.,  0.,  6.,\n",
       "        1.,  5.,  5.,  5.,  1.,  9.,  3.,  5.,  5.,  5.,  5., 10.,  8.,\n",
       "        5.,  7.,  5.,  5.,  5.,  2.,  9.,  5.,  9.,  1.,  9.,  9.,  7.,\n",
       "        4.,  5.,  6.,  5.,  5.,  5.,  5.,  5.,  5., 10.,  0.,  5.,  0.,\n",
       "        5.,  0.,  0.,  5.,  0.,  1.,  5.,  1.,  0.,  0.,  1.,  5.,  5.,\n",
       "        0.,  9., 10.,  9.,  0.,  4.,  5.,  0.,  0.,  0.,  5.,  5.,  5.,\n",
       "        5.,  2.,  0.,  5.,  8.,  5.,  9.,  0.,  3.,  0.,  5.,  0.,  0.,\n",
       "        5.,  4.,  1.,  5.,  5.,  0.,  5.,  5.,  5.,  0.,  9.,  0.,  8.,\n",
       "        0.,  6.,  0.,  5.,  0.,  4.,  5.,  5.,  9.,  0., 10.,  5.,  8.,\n",
       "        1.,  9.,  0.,  2.,  0.,  7.,  5.,  1.,  0.,  5.,  0.,  0.,  5.,\n",
       "        5.,  5.,  5.,  5.,  9.,  5.,  5., 10.,  9.,  8.,  5.,  0.,  9.,\n",
       "        1., 10.,  0., 10.,  9.,  5.,  4.,  5.,  5.,  5.,  9.,  0.,  0.,\n",
       "        0.,  9.,  5.,  5.,  5.,  3.,  5.,  5.,  3.,  0.,  0.,  0.,  5.,\n",
       "        0.,  1.,  5.,  5.,  5.,  5.,  5.,  7.,  7.,  0.,  5.,  9.,  0.,\n",
       "        6.,  2.,  5.,  5.,  5.,  5.,  0.,  2.,  0.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  6.,  5.,  5.,  5.,  5.,  5.,  5.,  0.,  7.,  5.,  3.,\n",
       "        5.,  5.,  0., 10.,  5.,  3.,  0.,  9.,  5.,  8.,  5.,  1.,  1.,\n",
       "        5.,  8.,  8.,  9.,  0.,  5.,  1.,  1.,  1.,  5.,  9.,  5.,  0.,\n",
       "        0.,  0.,  5.,  5.,  5.,  9.,  5., 10.,  1.,  9.,  9.,  0.,  3.,\n",
       "        5.,  5.,  8.,  5.,  5.,  5.,  0.,  5.,  5.,  9.,  0.,  9.,  9.,\n",
       "        0.,  5.,  2.,  5.,  1.,  5.,  9.,  5.,  5.,  5.,  5.,  0.,  9.,\n",
       "        2.,  5.,  8.,  1., 10.,  6.,  5.,  0.,  0.,  8.,  2.,  0.,  5.,\n",
       "       10.,  5.,  5.,  5.,  9.,  5.,  0.,  5.,  9.,  9.,  0.,  4.,  3.,\n",
       "        0.,  5.,  1.,  0.,  9.,  0.,  5.,  5.,  1.,  5.,  1.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  0.,  5.,  5.,  5.,  5.,  2.,  1.,  5.,  0.,\n",
       "        9.,  7.,  5.,  6.,  3.,  5.,  2.,  0.,  1.,  5.,  8.,  0.,  0.,\n",
       "        6.,  0.,  0.,  0.,  0.,  9.,  5.,  5.,  5.,  2.,  5.,  0.,  1.,\n",
       "        5.,  0.,  6.,  9.,  5.,  6.,  5.,  5.,  0.,  5.,  7.,  8.,  0.,\n",
       "        2.,  1.,  5.,  9.,  5.,  5.,  9.,  5.,  5.,  1.,  0.,  3.,  9.,\n",
       "        0.,  3.,  5.,  5.,  2.,  2.,  5.,  5.,  9.,  5.,  4.,  9.,  2.,\n",
       "        5.,  9.,  9.,  1.,  0.,  5.,  1.,  0.,  0.,  2.,  9.,  4.,  0.,\n",
       "        9.,  5.,  5.,  5.,  5.,  5.,  0.,  1.,  1.,  2.,  4.,  0.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  0.,  6.,  5.,  5.,  0.,  5.,  5.,  5.,\n",
       "        2.,  5.,  5., 10.,  5.,  2.,  1.,  2.,  0.,  9.,  6.,  5.,  5.,\n",
       "        8.,  5., 10.,  0.,  2.,  0.,  2.,  5.,  1.,  5.,  1.,  5.,  0.,\n",
       "        7.,  1.,  5.,  1.,  5.,  5.,  0.,  9.,  0.,  5.,  8.,  5., 10.,\n",
       "        5.,  2.,  3.,  5.,  5.,  5.,  5.,  5.,  6.,  6.,  0.,  0.,  2.,\n",
       "        3.,  5.,  6.,  5.,  5.,  7.,  5.,  5.,  9.,  5.,  0.,  5.,  0.,\n",
       "        5.,  5.,  0.,  0.,  5.,  5.,  2.,  2.,  5.,  0.,  3.,  6.,  5.,\n",
       "        5.,  1.,  0.,  5.,  0.,  5.,  2.,  6.,  0.,  5.,  5.,  1.,  0.,\n",
       "        5.,  0.,  5.,  5.,  5.,  0.,  0.,  3.,  5.,  5.,  5.,  5.,  9.,\n",
       "       10.,  5.,  5.,  5.,  5.,  3.,  2.,  5.,  2.,  5.,  5.,  5.,  2.,\n",
       "        5.,  5.,  2.,  0.,  0.,  3.,  1.,  0.,  5.,  0.,  5.,  7.,  0.,\n",
       "        9.,  2.,  5.,  1.,  3.,  8.,  9.,  5.,  5.,  0.,  5.,  5.,  5.,\n",
       "        5.,  9.,  5.,  0.,  8.,  5.,  0.,  5.,  9.,  5.,  0.,  5.,  0.,\n",
       "        9.,  0.,  5.,  5.,  1.,  5.,  9.,  5.,  0.,  0.,  9.,  0.,  9.,\n",
       "        5.,  0.,  1.,  5.,  0.,  0.,  0.,  5.,  9.,  5.,  0.,  3.,  4.,\n",
       "       10.,  5.,  5.,  5.,  5.,  9.,  5.,  5.,  5.,  2.,  0.,  5.,  5.,\n",
       "       10.,  0.,  5.,  5.,  5.,  9.,  5.,  1.,  5.,  8.,  5.,  1.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "researchmentPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
